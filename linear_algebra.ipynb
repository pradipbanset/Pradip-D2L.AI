{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3.), tensor(-1.), tensor(2.), tensor(0.5000), tensor(1.))"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(1.0)\n",
    "y = torch.tensor(2.0)\n",
    "\n",
    "x+y, x-y, x*y, x/y, x**y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x  = torch.arange(3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A =  torch.arange(6).reshape(3,2)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2, 4],\n",
       "        [1, 3, 5]])"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True]])"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.tensor([[1,2,3],[2,1,2],[3,2,1]])\n",
    "A == A.T     #Symmetric matrices are the subset of square matrices that are equal to their own transposes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(24).reshape(2,3,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Properties of Tensor Arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 2.],\n",
       "         [3., 4., 5.]]),\n",
       " tensor([[ 0.,  2.,  4.],\n",
       "         [ 6.,  8., 10.]]))"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(6, dtype=torch.float32).reshape(2,3)\n",
    "B = A.clone()  #Assign a copy of A to B by allocating new memory\n",
    "A, A+B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  4.],\n",
       "        [ 9., 16., 25.]])"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A*B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 2,  3,  4,  5],\n",
       "          [ 6,  7,  8,  9],\n",
       "          [10, 11, 12, 13]],\n",
       " \n",
       "         [[14, 15, 16, 17],\n",
       "          [18, 19, 20, 21],\n",
       "          [22, 23, 24, 25]]]),\n",
       " torch.Size([2, 3, 4]))"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 2\n",
    "X = torch.arange(24).reshape(2,3,4)\n",
    "a + X, (a*X).shape    #Adding or multiplying a scalar and a tensor produces a result with the same shape as the original tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2.]), tensor(3.))"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(3, dtype=torch.float32)\n",
    "x, x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), tensor(15.))"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, A.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([3]))"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, A.sum(axis=0).shape   #axis = 0 refers the rows and axis = 1 refers the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([2]))"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, A.sum(axis=1).shape #specifying axis=1 reduces the colummn dimension by summing up elements of all the columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sum(axis=[0,1]) == A.sum() #Reducing a matrix along both rows and columns via summation is equivalent to summing up all the elements of the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5000)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A.mean()\n",
    "A.sum() / A.numel() #The function numel gives the number of elements in a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.5000, 2.5000, 3.5000]), tensor([1.5000, 2.5000, 3.5000]))"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.mean(axis=0), A.sum(axis=0) / A.shape[0] #A direct, built-in method that is concise and optimized\n",
    "                                           #A manual way of achieving the same result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-Reduction Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 3.],\n",
       "         [12.]]),\n",
       " torch.Size([2, 1]))"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_A = A.sum(axis=1, keepdims=True)\n",
    "sum_A, sum_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.3333, 0.6667],\n",
       "        [0.2500, 0.3333, 0.4167]])"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A / sum_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.],\n",
       "        [3., 5., 7.]])"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.cumsum(axis=0) #The function cumsum performs a cumulative sum over the elements of the tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dot Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2.]), tensor([1., 1., 1.]), tensor(3.))"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.ones(3, dtype=torch.float32)\n",
    "x, y, torch.dot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(x*y) #The dot product of two vectors is the sum of the products of the elements at the same position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix–Vector Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([3]), tensor([ 5., 14.]), tensor([ 5., 14.]))"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, x.shape, torch.mv(A,x), A@x #erforming matrix-vector multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix–Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 3.,  3.,  3.,  3.],\n",
       "         [12., 12., 12., 12.]]),\n",
       " tensor([[ 3.,  3.,  3.,  3.],\n",
       "         [12., 12., 12., 12.]]))"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B =  torch.ones(3,4)\n",
    "torch.mm(A,B), A@B  #Matrix-matrix multiplication\n",
    "\n",
    "#Matrix-Matrix Multiplication: If A and B are both 2D tensors (matrices), A @ B performs matrix-matrix multiplication.\n",
    "#Matrix-Vector Multiplication: If A is a 2D tensor (matrix) and B is a 1D tensor (vector), A @ B performs matrix-vector multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = torch.tensor([3.0, -4.0])\n",
    "torch.norm(u) #The norm of a vector is a nonnegative scalar that describes the length of the vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(u).sum() #The L1 norm of a vector is the sum of the absolute values of its components                                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(torch.ones((4,9))) #The L2 norm of a vector is the square root of the sum of the squares of the vector’s elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prove that the transpose of the transpose of a matrix is the matrix itself: (AT)T = A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor mat_A:  tensor([[0, 1],\n",
      "        [2, 3],\n",
      "        [4, 5]])\n",
      "Transpose of mat_A:  tensor([[0, 2, 4],\n",
      "        [1, 3, 5]])\n",
      "Transpose of Transpose of mat_A:  tensor([[0, 1],\n",
      "        [2, 3],\n",
      "        [4, 5]])\n"
     ]
    }
   ],
   "source": [
    "mat_A = torch.arange(6).reshape(3,2)\n",
    "#mat_A\n",
    "\n",
    "transpose_A = mat_A.T\n",
    "\n",
    "transpose_of_transpose = transpose_A.T\n",
    "\n",
    "print(\"Tensor mat_A: \", mat_A)\n",
    "\n",
    "print(\"Transpose of mat_A: \", transpose_A)\n",
    "\n",
    "print(\"Transpose of Transpose of mat_A: \", transpose_of_transpose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given two matrices A and B show that sum and transposition commute: AT + BT = (A+B)T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix M: tensor([[1., 2., 3.],\n",
      "        [1., 1., 1.]])\n",
      "Matrix V: tensor([[1., 1., 1.],\n",
      "        [1., 2., 3.]])\n",
      "Transpose M: tensor([[1., 1.],\n",
      "        [2., 1.],\n",
      "        [3., 1.]])\n",
      "Transpose V: tensor([[1., 1.],\n",
      "        [1., 2.],\n",
      "        [1., 3.]])\n",
      "Sum of the two matrices:  tensor([[2., 3., 4.],\n",
      "        [2., 3., 4.]])\n",
      "Sum of the trnaspose of the two matrices:  tensor([[2., 2.],\n",
      "        [3., 3.],\n",
      "        [4., 4.]])\n",
      "Transpose of the sum of the two:  tensor([[2., 2.],\n",
      "        [3., 3.],\n",
      "        [4., 4.]])\n"
     ]
    }
   ],
   "source": [
    "M = torch.Tensor([[1,2,3],[1,1,1]])\n",
    "V = torch.Tensor([[1,1,1],[1,2,3]])\n",
    "\n",
    "print(\"Matrix M:\", M)\n",
    "print(\"Matrix V:\", V)\n",
    "\n",
    "\n",
    "M_T = M.T\n",
    "V_T = V.T\n",
    "\n",
    "print(\"Transpose M:\", M_T)\n",
    "print(\"Transpose V:\", V_T)\n",
    "\n",
    "sum_of_mat = (M + V)\n",
    "print(\"Sum of the two matrices: \", sum_of_mat)\n",
    "\n",
    "trans_sum = (M_T + V_T)\n",
    "print(\"Sum of the trnaspose of the two matrices: \", trans_sum)\n",
    "\n",
    "trans_of_sum = sum_of_mat.T\n",
    "print(\"Transpose of the sum of the two: \",trans_of_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given any square matrix A, is A + AT(transpose) always symetric? Can you prove the result by using only the results of the previous two exercises?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transpose of A is:  tensor([[0.2099, 0.9843],\n",
      "        [0.9767, 0.0803]])\n",
      "Sum of A and its transpose is:  tensor([[0.4198, 1.9610],\n",
      "        [1.9610, 0.1605]])\n",
      "Is the sum of A and its transpose symmetric?  True\n"
     ]
    }
   ],
   "source": [
    "#A = torch.tensor([[1,2],[3,4]])\n",
    "A = torch.rand(2, 2)\n",
    "A_T = A.T\n",
    "print(\"Transpose of A is: \", A_T)\n",
    "\n",
    "result = A + A_T\n",
    "print(\"Sum of A and its transpose is: \", result)\n",
    "\n",
    "#Now check whether the sum of A and its transpose is symmetric or not\n",
    "#is_symmmetric = (result == result.T)\n",
    "is_symmmetric = torch.equal(result, result.T)  #Compares two tensors element by element to check if they are exactly equal in terms of both shape and values.\n",
    "print(\"Is the sum of A and its transpose symmetric? \", is_symmmetric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We defined the tensor X of shape (2, 3, 4) in this section. What is the output of len(X)? Write your answer without implementing any code, then check your answer using code.\n",
    "\n",
    "ans -> 2\n",
    "The function len(X) in PyTorch (or NumPy) returns the size of the first dimension of the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(2,3,4)\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a tensor X of arbitrary shape, does len(X) always correspond to the length of a certain axis of X? What is that axis?\n",
    "\n",
    "ans -> Yes, for tensor X of arbiratory shape, the output of len(X) always corresponds to the length of the first axis (axis=0) of X\n",
    "\n",
    "the axis of a tensor are numbers starting form 0, correspondings to its dimensions\n",
    "axis = 0 : first dimension \n",
    "axis = 1 : second dimension \n",
    "axis = 2 : third dimension and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#function len(X) always returns the size of axis \n",
    "X = torch.tensor([[10,20,30],[40,50,60],[70,80,90],[100,110,120]])\n",
    "#X.shape\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run A / A.sum(axis=1) and see what happens. Can you analyze the results?\n",
    "Row-wise Sum: Each row in A is summed, producing a column vector\n",
    "Element-wise Division: Each element in A is divided by the corresponding row sum This operation normalizes each row so that the sum of elements in each row becomes 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1769, 0.9175],\n",
       "        [0.8295, 0.0754]])"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A / A.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When traveling between two points in downtown Manhattan, what is the distance that you need to cover in terms of the coordinates, i.e., in terms of avenues and streets? Can you travel diagonally?\n",
    "\n",
    "The distance between two points in terms of avenues and streets is called the Manhattan distance, and it’s calculated as the sum of the absolute differences in avenue and street coordinates:\n",
    "Manhattan Distance = |Avenue2 - Avenue1| + |Street2 - Street1|\n",
    "\n",
    "Diagonal travel is not usually possible in the strict sense within the Manhattan grid system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a tensor of shape (2, 3, 4). What are the shapes of the summation outputs along axes 0, 1, and 2?\n",
    "\n",
    "When summing a tensor along a specific axis, the resulting tensor's shape corresponds to the original shape with the summed axis removed.\n",
    "\n",
    "Expected Output Shapes:\n",
    "Axis 0: (3,4)\n",
    "Axis 1: (2,4)\n",
    "Axis 2: (2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11]],\n",
      "\n",
      "        [[12, 13, 14, 15],\n",
      "         [16, 17, 18, 19],\n",
      "         [20, 21, 22, 23]]])\n",
      "When axis = 0:  tensor([[12, 14, 16, 18],\n",
      "        [20, 22, 24, 26],\n",
      "        [28, 30, 32, 34]])\n",
      "When axis = 1:  tensor([[12, 15, 18, 21],\n",
      "        [48, 51, 54, 57]])\n",
      "When axis = 2:  tensor([[ 6, 22, 38],\n",
      "        [54, 70, 86]])\n"
     ]
    }
   ],
   "source": [
    "X = torch.arange(24).reshape(2,3,4)\n",
    "print(X)\n",
    "\n",
    "#when axis = 0\n",
    "axis_0 = X.sum(axis=0)\n",
    "print(\"When axis = 0: \", axis_0)\n",
    "\n",
    "#when axis = 1\n",
    "axis_1 = X.sum(axis=1)\n",
    "print(\"When axis = 1: \", axis_1)\n",
    "\n",
    "#when axis = 2\n",
    "axis_2 = X.sum(axis=2)\n",
    "print(\"When axis = 2: \", axis_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed a tensor with three or more axes to the linalg.norm function and observe its output. What does this function compute for tensors of arbitrary shape?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.,  2.,  3.],\n",
      "         [ 4.,  5.,  6.,  7.],\n",
      "         [ 8.,  9., 10., 11.]],\n",
      "\n",
      "        [[12., 13., 14., 15.],\n",
      "         [16., 17., 18., 19.],\n",
      "         [20., 21., 22., 23.]]])\n",
      "Full norm:  tensor(65.7571)\n",
      "Norm along axis 0:  tensor([[12.0000, 13.0384, 14.1421, 15.2971],\n",
      "        [16.4924, 17.7200, 18.9737, 20.2485],\n",
      "        [21.5407, 22.8473, 24.1661, 25.4951]])\n",
      "Norm along axis 1:  tensor([[ 8.9443, 10.3441, 11.8322, 13.3791],\n",
      "        [28.2843, 29.9833, 31.6860, 33.3916]])\n",
      "Norm along axis 2:  tensor([[ 3.7417, 11.2250, 19.1311],\n",
      "        [27.0924, 35.0714, 43.0581]])\n"
     ]
    }
   ],
   "source": [
    "Z = torch.arange(24).reshape(2,3,4).float()\n",
    "print(Z)\n",
    "\n",
    "norm_full = torch.linalg.norm(Z) #takes the square of each element and then add them all together and then take the square root of the sum\n",
    "print(\"Full norm: \", norm_full)\n",
    "\n",
    "norm_0 = torch.linalg.norm(Z, axis=0)\n",
    "print(\"Norm along axis 0: \", norm_0)    \n",
    "\n",
    "norm_1 = torch.linalg.norm(Z, axis=1)\n",
    "print(\"Norm along axis 1: \", norm_1) \n",
    "\n",
    "norm_2 = torch.linalg.norm(Z, axis=2)\n",
    "print(\"Norm along axis 2: \", norm_2) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
